{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_workshop_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2yyBoq9OiXs",
        "colab_type": "text"
      },
      "source": [
        "# 敵対的生成ネットワーク研究会\n",
        "第一回のURL（ホワイトボードのURLは本日限りの短縮URLなので、こちらを保存しておいてください）：\n",
        "https://colab.research.google.com/drive/1egFCcIXzM7xtlXWRp9wFjDSocL5j94oP\n",
        "\n",
        "## 本研究会の目的\n",
        "機械学習のフィールドで一世を風靡したGANについて研究する。\n",
        " - 原理を理解する\n",
        " - 使ってみる\n",
        " - 学習してみる\n",
        " - 実装できるようになる\n",
        " - ビジネスへの応用について考えてみる\n",
        " - GANのアルゴリズムを発展させる（難関！）\n",
        "\n",
        "\n",
        " ## 本日の目的\n",
        " 本日は、GANについては軽く触れる程度に留め、以下について実際にやってみながら勉強して行きます。\n",
        "\n",
        "**GANに向かって行く一本筋の道のり**\n",
        " - Google Colaboratoryの使い方\n",
        " - TensorFlowの使い方（v2を見据えて…）\n",
        " - 機械学習の基礎\n",
        " - ニューラルネットワーク\n",
        " - 畳み込みニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9EkSiatpKjl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GPUを用いて高速に実行できる機械学習ライブラリ\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "# 結果をプロットするためのライブラリ\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdiI-CGRAfuH",
        "colab_type": "text"
      },
      "source": [
        "# GANとは何か？\n",
        "- Generative Adversarial Networks（敵対的生成ネットワーク）\n",
        "- 入力の生成過程をモデル化する（生成モデル）ニューラルネットワーク\n",
        "- 教師なし学習（ラベル付きデータがいらない）\n",
        "\n",
        "https://www.imagazine.co.jp/gan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76803PSALKZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title デモ用ファイルの準備\n",
        "import os\n",
        "if not os.path.exists('fashion_mnist_generator'):\n",
        "  !wget -O fashion_mnist_generator.zip \"https://drive.google.com/uc?export=download&id=1-9h71kdd7WLKPNqa-v4iU0xjGprdRSea\"\n",
        "  !unzip fashion_mnist_generator.zip && rm fashion_mnist_generator.zip\n",
        "generator = tf.contrib.saved_model.load_keras_model('fashion_mnist_generator')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnVyygDde02S",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GANの学習に使ったデータセット\n",
        "#@markdown https://github.com/zalandoresearch/fashion-mnist\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# 画像を並べる数\n",
        "rows = 5\n",
        "cols = 10\n",
        "\n",
        "ds = tfds.image.mnist.FashionMNIST()\n",
        "ds.download_and_prepare()\n",
        "dataset = ds.as_dataset()['train']\n",
        "def preprocess(data):\n",
        "  img = tf.cast(data['image'], tf.float32)/255.\n",
        "  return tf.image.resize_bilinear([img], (32,32))[0], tf.one_hot(data['label'], 10)\n",
        "dataset = dataset.map(preprocess)\n",
        "\n",
        "for image, label in dataset.shuffle(1000).batch(rows*cols).take(1):\n",
        "  image = image.numpy()\n",
        "  if image.shape[3] == 1:\n",
        "    image = image[:,:,:,0]\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "for i in range(rows):\n",
        "  for j in range(cols):\n",
        "    plt.subplot(rows, cols, i*cols+j+1)\n",
        "    plt.imshow(image[i*cols+j], cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "    plt.clim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3szuSq2mGi_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GANが生成する画像を見てみる\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# 画像を並べる数\n",
        "rows = 5\n",
        "cols = 10\n",
        "\n",
        "noise = tf.random_normal((rows*cols,)+generator.input_shape[1:])\n",
        "image = generator(noise, training=False)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "image = image.numpy()\n",
        "if image.shape[3] == 1:\n",
        "  image = image[:,:,:,0]\n",
        "image = (image + 1.)/2.\n",
        "\n",
        "for i in range(rows):\n",
        "  for j in range(cols):\n",
        "    plt.subplot(rows, cols, i*cols+j+1)\n",
        "    plt.imshow(image[i*cols+j], cmap='gray_r')\n",
        "    plt.axis('off')\n",
        "    plt.clim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhz5s7OoCMlN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GANは与えられた数値を基に画像を生成する\n",
        "n = 10\n",
        "\n",
        "# 128次元ベクトルをランダムに二つ生成する\n",
        "noise1 = tf.random_normal((1,)+generator.input_shape[1:])\n",
        "noise2 = tf.random_normal((1,)+generator.input_shape[1:])\n",
        "\n",
        "# 二つを内分する128次元ベクトルをn個生成する\n",
        "p = tf.reshape(tf.linspace(0.,1.,n), [-1,1,1,1])\n",
        "noise = (1-p)*noise1 + p*noise2\n",
        "\n",
        "# 全てのベクトルから画像を生成する\n",
        "image = generator(noise, training=False)\n",
        "image = image.numpy()\n",
        "if image.shape[3] == 1:\n",
        "  image = image[:,:,:,0]\n",
        "image = (image + 1.)/2.\n",
        "\n",
        "# 各ベクトル（見やすいように最初の10次元だけ）と対応する画像を表示\n",
        "plt.figure(figsize=(12,5))\n",
        "for i in range(n):\n",
        "  plt.subplot(2, n, i+1)\n",
        "  noise_i = noise[i,0,0,:10].numpy()\n",
        "  lim = max(abs(noise_i))\n",
        "  plt.bar(range(10), noise_i)\n",
        "  plt.ylim(-lim, lim)\n",
        "  plt.axis('off')\n",
        "  plt.subplot(2, n, n+i+1)\n",
        "  plt.imshow(image[i], cmap='gray_r')\n",
        "  plt.axis('off')\n",
        "  plt.clim(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIIA6_QcX1Lt",
        "colab_type": "text"
      },
      "source": [
        "#TensorFlowによる数値計算"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q21RgIFBYdmF",
        "colab_type": "text"
      },
      "source": [
        "## スカラーの計算\n",
        "- TensorFlowでは数値をtf.Tensorとして扱う。Python上の数値とは区別される。\n",
        "- Tensorは数値型（dtype）を持っており、Python上の数値よりも明示的。\n",
        "- TensorFlow上の定数であることを示すためにtf.constantを使用する。定数もtf.Tensorとして扱われる。\n",
        "- Pythonの演算子を使ってtf.Tensor同士の演算を記述することができる。\n",
        "- Tensor同士の演算結果もやはりtf.Tensorとして扱われる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5NXGHWsXUkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i = tf.constant(1)\n",
        "print ('i =', i)\n",
        "\n",
        "x = tf.constant(1.)\n",
        "a = tf.constant(2.)\n",
        "b = tf.constant(3, dtype=tf.float32)\n",
        "c = tf.constant(4.)\n",
        "y = a * x**2 + b * x + c\n",
        "# 2 x 1^2 + 3 x 1 + 4 = 9\n",
        "print('y =', y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klgK-0O3aCfp",
        "colab_type": "text"
      },
      "source": [
        "## テンソルの基本的な計算\n",
        "- テンソルは基本的に数値の多次元配列であり、次元数をランクと呼ぶ。スカラーはランク0のテンソル。\n",
        "- Pythonのリストを使ってテンソルを記述する。また、TensorFlowの関数を用いて様々なテンソルを表現できる。\n",
        "- テンソルの要素はPythonの配列と同様に参照できる。\n",
        "- テンソルの各次元のサイズはtf.shapeを使って取得する。Shape自体がランク1のTensorとなっている。\n",
        "- テンソル同士の四則演算やテンソルのべき乗などは要素毎の演算となる。\n",
        "- 要素毎の演算の際、片方のテンソルにおいてある次元が1の場合、ブロードキャストというルールが適用される。\n",
        "- ランク2のテンソルを行列とみなして行列の積を計算できる（tf.matmul）。\n",
        "- その他、特定の次元に沿って平均を求めたり（tf.reduce_mean）できる。\n",
        "- Numpyを使ったことがある方は、TensorFlowにもほぼ同じ演算がほぼ同じインターフェースで用意されていると考えて頂いて結構です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofg-zTV0eD-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.constant([[1,2,3], [4,5,6]], dtype=tf.float32)\n",
        "print('x =', x) # Pythonのリストで定数を記述\n",
        "print('zeros =', tf.zeros([3,1])) # 全ての要素が0のテンソル\n",
        "print('ones =', tf.ones([3,2])) # 全ての要素が1のテンソル\n",
        "print('eye =', tf.eye(3)) # 3x3の単位行列\n",
        "print('random =', tf.random.uniform([2,5])) # 各要素が0以上1未満の乱数となっているテンソル\n",
        "\n",
        "print('x[0,1] =', x[0,1]) # 要素の参照\n",
        "print('x[:,1] =', x[:,1]) # 列ベクトルの参照\n",
        "\n",
        "y = tf.constant([[7.,8.,9.]])\n",
        "print('y =', y)\n",
        "x_plus_y = x + y # [2,3]と[1,3]なので足せる（最初の次元にブロードキャストが適用される）\n",
        "print('x+y', x_plus_y) # この場合、[7,8,9]を最初の次元に沿ってコピーした[[7,8,9], [7,8,9]]をxに足すのと同じ\n",
        "\n",
        "a = tf.constant([[1.,2.],[3.,4.]])\n",
        "b = tf.constant([[5.,6.],[7.,8.]])\n",
        "print('a * b =', a * b)\n",
        "print('matmul(a, b) =', tf.matmul(a, b))\n",
        "\n",
        "print('shape(x) =', tf.shape(x)) # 元のshapeは[2, 3]\n",
        "z = tf.reduce_mean(x, 0) # 最初の次元に沿って平均を求める\n",
        "print('z =', z) # [(1+4)/2, (2+5)/2, (3+6)/2]\n",
        "print('shape(z) =', tf.shape(z)) # 最初の次元がなくなって結果のshapeは[3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laGAPaOYp52y",
        "colab_type": "text"
      },
      "source": [
        "## 二次関数をプロットしてみる\n",
        "- x軸を細かく分割して各々についてyを求める。\n",
        "- パフォーマンスのためには、for文を使わずに、全てのxについての演算を一度に行う（重要）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY7TQ79Ep5Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.linspace(-5., 5., 100) # -5から+5までを100等分した配列（[-5.0, -4.9, ..., 5.0]）\n",
        "a = tf.constant(1.)\n",
        "b = tf.constant(2.)\n",
        "c = tf.constant(3.)\n",
        "y = a * x**2 + b * x + c # a,b,cはスカラーだが、xの要素は100個あるのでブロードキャストされる\n",
        "\n",
        "plt.plot(x, y) # matplotlibを用いてプロット"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8FN50ukrhi8",
        "colab_type": "text"
      },
      "source": [
        "## 変数\n",
        "- テンソルは、定数や演算結果を表すオブジェクトなので、値の変更はできない。一方で、変数は定義した後で値を変更できる。\n",
        "- 変数はtf.Variableとして扱われる。演算としてはtf.Tensorと同様に扱える（結果はやはりtf.Tensor）。\n",
        "- tf.get_variableで作ってassignなどのメソッドで値を代入する。普通に=を使って代入すると、tf.Variableが入っていたPython変数に別の値が代入されるだけ（Python上の普通の代入文）なので注意。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOIBab78rncd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.get_variable('x', initializer=1.) # 名前と初期値を指定して変数を作る\n",
        "print('x =', x)\n",
        "x.assign(3.)\n",
        "print('x =', x)\n",
        "x.assign_add(0.5) # 現在の値に0.5を足したものを再び代入する\n",
        "print('x =', x)\n",
        "\n",
        "# shapeだけ指定すると初期値はランダムになる\n",
        "y = tf.get_variable('y', [2,3])\n",
        "print('y =', y.numpy()) # tf.Tensorもtf.Variableもnumpyメソッドで値だけ取り出せる\n",
        "y.assign(tf.ones([2,3]))\n",
        "print('y =', y.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZYxwyDaJmqq",
        "colab_type": "text"
      },
      "source": [
        "#TensorFlowによる機械学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w14x7L9lsbZ",
        "colab_type": "text"
      },
      "source": [
        "## 勾配法（関数の最小化）\n",
        "- 坂を下るように関数の値を小さくして行き、最小値（正確には極小値）を取る点を探す手法。\n",
        "- 微分可能な関数に適用可能：関数が複雑で全貌がわからなくても、現在の点での傾きは求められることが多い。\n",
        "- TensorFlowなどの機械学習ライブラリの多くは、微分を自動でやってくれる！"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMfqVC4COvtA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title 関数の定義\n",
        "x = tf.get_variable('x', initializer=3.) # 初期値3の変数\n",
        "\n",
        "# お馴染みの二次関数\n",
        "def func(x):\n",
        "  a = tf.constant(1.)\n",
        "  b = tf.constant(2.)\n",
        "  c = tf.constant(3.)\n",
        "  return a * x**2 + b * x + c\n",
        "\n",
        "# xの位置でグラフが右肩上がり（dx/dyが正）ならばxを小さく、左肩上がり（dx/dyが負）ならばxを大きくする。\n",
        "# これを繰り返すとxはグラフの極小点に近づいて行く。\n",
        "def update(x):\n",
        "  with tf.GradientTape() as g: # GradientTapeのコンテキストの中で変数を使って計算すると\n",
        "    y = func(x)\n",
        "  dydx = g.gradient(y, x) # その変数による微分（dy/dx）を求めることができる\n",
        "  x.assign_sub(dydx * 0.1) # 変数xからdy/dx * 0.1を引いたものを再びxに代入する\n",
        "\n",
        "#グラフと現在のxをプロット\n",
        "def plot(x):\n",
        "  _x = tf.linspace(-5., 5., 100)\n",
        "  _y = func(_x)\n",
        "  plt.plot(_x, _y)\n",
        "  y = func(x)\n",
        "  plt.scatter(x.numpy(), y.numpy(), c='red')\n",
        "  plt.text(x.numpy(), y.numpy(), 'x={}'.format(x.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDVrDtYf4-LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 値の更新とプロット\n",
        "update(x)\n",
        "plot(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT0DOPSBly4d",
        "colab_type": "text"
      },
      "source": [
        "## 勾配法で回帰問題（関数の近似）を解く\n",
        "何かやりたいこと（機械にやらせたいこと）があった時、\n",
        "その目的の達成度を滑らかな関数（目的関数またはloss関数）としてうまく表現することができれば、機械学習は実現できる。\n",
        "\n",
        "\n",
        "ここでは、与えられた各$x$について、正解の二次曲線$y=ax^2+bx+c$と近似する二次曲線$\\tilde{y}=\\tilde{a}x^2+\\tilde{b}x+\\tilde{c}$との$y$軸上の二乗距離（$(\\tilde{y}-y)^2$）を求め、これらの平均値を目的関数とした。この目的関数を小さくするように近似曲線のパラメータ（$\\tilde{a}$,$\\tilde{b}$,$\\tilde{c}$）を更新して行くことで、二つの近似曲線を正解の二次曲線に近づけることができる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XvxqFnq6w8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 二次関数（パラメータを指定できるようにする）\n",
        "def func(x, a, b, c):\n",
        "  return a * x**2 + b * x + c\n",
        "\n",
        "# xを-5から5までの範囲でランダムに50個与える（サンプリング）\n",
        "x = tf.random.uniform([50], -5., 5.)\n",
        "\n",
        "# 正解の関数\n",
        "a = tf.constant(1.)\n",
        "b = tf.constant(2.)\n",
        "c = tf.constant(3.)\n",
        "y = func(x, a, b, c)\n",
        "\n",
        "# 近似曲線のパラメータ\n",
        "_a = tf.get_variable('a', ())\n",
        "_b = tf.get_variable('b', ())\n",
        "_c = tf.get_variable('c', ())\n",
        "\n",
        "# 勾配法で変数を更新\n",
        "def update(x, y, _a, _b, _c):\n",
        "  with tf.GradientTape() as g:\n",
        "    _y = func(x, _a, _b, _c)\n",
        "    loss = tf.reduce_mean((_y - y)**2) # 目的関数：y軸上の二乗距離の平均\n",
        "  da, db, dc = g.gradient(loss, [_a, _b, _c]) # 目的関数をパラメータで微分して勾配を求める\n",
        "  _a.assign_sub(da * 0.002)\n",
        "  _b.assign_sub(db * 0.002)\n",
        "  _c.assign_sub(dc * 0.002)\n",
        "\n",
        "# 正解曲線とその上のサンプル点、さらに近似曲線をプロット\n",
        "def plot(x, y, a, b, c, _a, _b, _c):\n",
        "  x_axis = tf.linspace(-5., 5., 100)\n",
        "  y_axis = func(x_axis, a, b, c)\n",
        "  _y_axis = func(x_axis, _a, _b, _c)\n",
        "  plt.plot(x_axis, y_axis)\n",
        "  plt.plot(x_axis, _y_axis)\n",
        "  plt.scatter(x, y)\n",
        "  plt.ylim([tf.reduce_min(y_axis).numpy(), tf.reduce_max(y_axis).numpy()])\n",
        "  plt.title('$\\\\tilde{{y}}=({:.2f})x^2+({:.2f})x+({:.2f})$'.format(_a.numpy(), _b.numpy(), _c.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_NXMXBSUqlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title パラメータ更新\n",
        "update(x, y, _a, _b, _c)\n",
        "plot(x, y, a, b, c, _a, _b, _c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BfjdEmfOo3A",
        "colab_type": "text"
      },
      "source": [
        "## ニューラルネットワーク\n",
        "- 脳の神経回路を模した学習機械\n",
        "- ニューロンを模した多入力1出力のユニットを多数つなぎ合わせて、（一般には）多入力多出力の関数を表現する。\n",
        "- ユニット間の結合重み（これはシナプスを模している）を変更することで、様々な関数を表現できる。\n",
        "- とにかくたくさんのパラメータを使って多種多様な関数を表現できる。\n",
        "- 色々な種類のネットワーク構造が提案されていますが、ここでは階層型ニューラルネットワークについて紹介します。\n",
        "\n",
        "https://ja.wikipedia.org/wiki/ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g44EVDK7OalX",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ニューラルネットワークの構築\n",
        "#@markdown tf.keras.layersの下に機械学習でよく使う層のクラスが定義されており、また、tf.keras.Modelを使うと、複数の層からなるネットワークの変数の管理が容易になる。\n",
        "\n",
        "# ニューラルネットワークの層を準備（必要な変数は自動で用意される）\n",
        "dense1 = tf.keras.layers.Dense(5) # n入力5出力の全結合層（nは前の層に応じて自動で決まる）\n",
        "relu1 = tf.keras.layers.ReLU() # 0以下の値を全て0にする\n",
        "dense2 = tf.keras.layers.Dense(5)\n",
        "relu2 = tf.keras.layers.ReLU()\n",
        "dense3 = tf.keras.layers.Dense(5)\n",
        "relu3 = tf.keras.layers.ReLU()\n",
        "dense4 = tf.keras.layers.Dense(1) # 1出力の最終層\n",
        "\n",
        "# 1入力、1出力のニューラルネットワーク\n",
        "x = tf.keras.Input([1])\n",
        "h1 = relu1(dense1(x))\n",
        "h2 = relu2(dense2(h1))\n",
        "h3 = relu3(dense3(h1))\n",
        "y = dense4(h3)\n",
        "neural_network = tf.keras.Model(inputs=x, outputs=y)\n",
        "\n",
        "# xを-1から1までの範囲でランダムに50個与える（サンプリング）\n",
        "x = tf.random.uniform([50, 1], -1., 1.)\n",
        "\n",
        "# 正解の関数\n",
        "def func(x):\n",
        "  return 1. * x**2 + 2. * x + 3.\n",
        "y = func(x)\n",
        "\n",
        "# 勾配法で変数を更新\n",
        "def update(x, y):\n",
        "  with tf.GradientTape() as g:\n",
        "    _y = neural_network(x)\n",
        "    loss = tf.reduce_mean((_y - y)**2) # 目的関数：y軸上の二乗距離の平均\n",
        "  variables = neural_network.trainable_variables\n",
        "  grads = g.gradient(loss, variables) # 目的関数をパラメータで微分して勾配を求める\n",
        "  for g, v in zip(grads, variables):\n",
        "    v.assign_sub(g*0.01)\n",
        "\n",
        "# 正解曲線とその上のサンプル点、さらに近似曲線をプロット\n",
        "def plot(x, y):\n",
        "  x_axis = tf.expand_dims(tf.linspace(-1., 1., 100), 1)\n",
        "  y_axis = func(x_axis)\n",
        "  _y_axis = neural_network(x_axis)\n",
        "  plt.plot(x_axis, y_axis)\n",
        "  plt.plot(x_axis, _y_axis)\n",
        "  plt.scatter(x, y)\n",
        "  plt.ylim([tf.reduce_min(y_axis).numpy(), tf.reduce_max(y_axis).numpy()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeBH22GeaBOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 自動で用意された変数\n",
        "print(dense2.kernel)\n",
        "print(dense2.bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M6hL6VvR2z6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title パラメータ更新\n",
        "for i in range(20):\n",
        "  update(x, y)\n",
        "plot(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g64pQddfbnYi",
        "colab_type": "text"
      },
      "source": [
        "## 畳み込みニューラルネットワーク\n",
        "- 画像に畳み込み（convolution）を施し、得られた特徴マップにさらに畳み込みを施す…といったことを繰り返して複雑な特徴を抽出するニューラルネットワーク。\n",
        "\n",
        "https://github.com/vdumoulin/conv_arithmetic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYinpNyabjuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv = tf.keras.layers.Conv2D(2, 3) # 3x3のカーネル二つからなる畳み込み層\n",
        "relu = tf.keras.layers.ReLU()\n",
        "x = tf.keras.Input([None, None, 1]) # サイズ未定で1チャンネル（グレースケール）の画像を想定した入力\n",
        "y = conv(x)\n",
        "y = relu(y)\n",
        "model = tf.keras.Model(inputs=x, outputs=y)\n",
        "\n",
        "# カーネルとバイアスを上書きして結果を見てみる\n",
        "kernel = [\n",
        "    [[1., 0., 0.],\n",
        "     [0., 1., 0.],\n",
        "     [0., 0., 1.]],\n",
        "\n",
        "    [[0., 0., 0.],\n",
        "     [1., 1., 1.],\n",
        "     [0., 0., 0.]],\n",
        "]\n",
        "bias = [\n",
        "    -1.8,\n",
        "    -2.\n",
        "]\n",
        "conv.kernel = tf.transpose(tf.reshape(kernel, [2,3,3,1]), [1,2,3,0])\n",
        "conv.bias = tf.constant(bias)\n",
        "\n",
        "for x, _ in dataset.batch(1).skip(2).take(1):\n",
        "  y = model(x)\n",
        "  \n",
        "channels = tf.shape(y)[3].numpy() # 出力チャネル数\n",
        "assert channels==2 # カーネルが二つなので2になるはず\n",
        "\n",
        "for i in range(channels):\n",
        "  plt.subplot(channels,3,i*3+1)\n",
        "  plt.imshow(x[0,:,:,0])\n",
        "  plt.axis('off')\n",
        "  plt.subplot(channels,3,i*3+2)\n",
        "  plt.imshow(conv.kernel[:,:,0,i])\n",
        "  plt.axis('off')\n",
        "  plt.subplot(channels,3,i*3+3)\n",
        "  plt.imshow(y[0,:,:,i])\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlzJb89h-Xf",
        "colab_type": "text"
      },
      "source": [
        "## 畳み込みニューラルネットワークによる画像の分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y048zKSQh88q",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title 畳み込みニューラルネットワークによる分類器の構築\n",
        "\n",
        "conv_layers = []\n",
        "x = tf.keras.Input([None, None, 1])\n",
        "\n",
        "# 畳み込みを繰り返し適用\n",
        "y = x\n",
        "for i in range(5):\n",
        "  conv = tf.keras.layers.Conv2D(12, 3, padding='SAME')\n",
        "  conv_layers.append(conv)\n",
        "  relu = tf.keras.layers.ReLU()\n",
        "  y = relu(conv(y))\n",
        "conv = tf.keras.layers.Conv2D(10, 3, padding='SAME') # 最後のチャネル数はクラス数で\n",
        "conv_layers.append(conv)\n",
        "y = conv(y)\n",
        "\n",
        "# ここまでで画像の各ピクセルには各クラスのスコア\n",
        "#（Tシャツっぽさ、スニーカーっぽさなど）が表現されている（そうなるようにこれから学習させる！）\n",
        "# 最後に全ピクセルの平均を取ることで多数決を取る\n",
        "y = tf.keras.layers.GlobalAveragePooling2D()(y)\n",
        "# Softmaxを使って各ユニットが確率を表すように正規化する\n",
        "y = tf.keras.layers.Activation('softmax')(y)\n",
        "model = tf.keras.Model(inputs=x, outputs=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS8i5g7G_3eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 畳み込みのカーネル\n",
        "conv = conv_layers[0]\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(conv.filters):\n",
        "  plt.subplot(1, conv.filters, i+1)\n",
        "  plt.imshow(conv.kernel[:,:,0,i], cmap='gray')\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1856JbPtpuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title 分類器の学習\n",
        "# @markdown 実はtf.keras.Modelには、勾配の計算と変数の更新を自動で行う機能が用意されています。ここではこれを使いますが、GANの学習は少し込み入っているため、これが使えません。GANの学習の際は、これまで通り明示的に勾配を求めて変数の更新を行います。\n",
        "\n",
        "model.compile(tf.train.AdamOptimizer(0.001), loss='categorical_crossentropy')\n",
        "model.fit(dataset.shuffle(1000).batch(64), epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO_I7UkssNkJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title 分類器の出力\n",
        "n = 10\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for i, (x, y) in enumerate(dataset.shuffle(1000).take(n)):\n",
        "  plt.subplot(2,n,i+1)\n",
        "  plt.imshow(x[:,:,0], cmap='gray_r')\n",
        "  plt.axis('off')\n",
        "  plt.subplot(2,n,n+i+1)\n",
        "  plt.plot(model(tf.expand_dims(x, 0))[0].numpy())\n",
        "  plt.plot(y.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsMA3XJnNV_r",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title 中間層の値\n",
        "sub_model = tf.keras.Model(inputs=model.inputs, outputs=conv_layers[-1].output)\n",
        "\n",
        "n = 5\n",
        "\n",
        "label_texts = [\n",
        "    'T-shirt/top',\n",
        "    'Trouser',\n",
        "    'Pullover',\n",
        "    'Dress',\n",
        "    'Coat',\n",
        "    'Sandal',\n",
        "    'Shirt',\n",
        "    'Sneaker',\n",
        "    'Bag',\n",
        "    'Ankle boot'\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "for x, y in dataset.shuffle(1000).batch(n).take(1):\n",
        "  hidden = sub_model(x)\n",
        "  #hidden -= tf.reduce_mean(hidden, -1, keepdims=True)\n",
        "  hidden = tf.nn.softmax(hidden)\n",
        "  \n",
        "for j, text in enumerate(label_texts):\n",
        "  plt.subplot(n+1,11,j+2)\n",
        "  plt.text(0,0,text)\n",
        "  plt.axis('off')\n",
        "for i in range(n):\n",
        "  plt.subplot(n+1,11,(i+1)*11+1)\n",
        "  plt.imshow(x[i,:,:,0], cmap='gray_r')\n",
        "  plt.axis('off')\n",
        "  for j in range(10):\n",
        "    plt.subplot(n+1,11,(i+1)*11+j+2)\n",
        "    plt.imshow(hidden[i,:,:,j], cmap='Reds' if y[i,j]>0. else 'Blues')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}