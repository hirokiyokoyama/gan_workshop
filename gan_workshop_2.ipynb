{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_workshop_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirokiyokoyama/gan_workshop/blob/master/gan_workshop_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa-BshP9X3F5",
        "colab_type": "text"
      },
      "source": [
        "# 敵対的生成ネットワーク研究会\n",
        "第一回のURL：\n",
        "https://colab.research.google.com/drive/1egFCcIXzM7xtlXWRp9wFjDSocL5j94oP\n",
        "\n",
        "第二回のURL：\n",
        "https://colab.research.google.com/drive/1t_QRi-V77uqIvJIhqvtwUVYOcsKZmK_A\n",
        "\n",
        "Slackに参加：\n",
        "https://join.slack.com/t/gan-workshop/shared_invite/enQtNzc0MzQ0NzQxODczLTA1NGNjNzM4OWRmN2U5OTYyNjM0YWE3MGQ1Mjk1YmM2YWYzNjExZTBkYjAzNTNiYWNmMWQzYWIzZmVmMjJiY2I\n",
        "\n",
        "横山のgithub（こちらにもノートブックが置いてあります）\n",
        "https://github.com/hirokiyokoyama/gan_workshop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG1eoEABKYIS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title 今回使うものの準備\n",
        "\n",
        "# GPUを用いて高速に実行できる機械学習ライブラリ\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "# 結果をプロットするためのライブラリ\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "layers = tf.keras.layers\n",
        "\n",
        "# 学習の安定のため、中間層の値を正規化するLayer\n",
        "class PixelwiseNormalization(tf.keras.layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(PixelwiseNormalization, self).__init__()\n",
        "  \n",
        "  def call(self, x):\n",
        "    n = tf.reduce_mean(tf.square(x), -1, keepdims=True)\n",
        "    n = tf.rsqrt(n + 1e-5)\n",
        "    return x * n\n",
        "\n",
        "# ミニバッチ内の特徴量の標準偏差をdiscriminatorの判別基準にするためのLayer\n",
        "# これによって本物の特徴量が多様ならば、偽物の特徴量も多様になるようにgeneratorが学習するようになる（mode collapse防止）\n",
        "# Discriminatorの最終層の手前などに入れて使う\n",
        "class MinibatchStddev(tf.keras.layers.Layer):\n",
        "  def __init__(self, group_size=1, num_new_features=1):\n",
        "    super(MinibatchStddev, self).__init__()\n",
        "    self._group_size = group_size\n",
        "    self._num_new_features = num_new_features\n",
        "\n",
        "  def call(self, x):\n",
        "    s = tf.shape(x) # [NHWC]  Input shape.\n",
        "    n = self._num_new_features\n",
        "    G = tf.minimum(self._group_size, s[0])\n",
        "\n",
        "    # [GMHWnc] Split minibatch into M groups of size G. Split channels into n channel groups c.\n",
        "    y = tf.reshape(x, [G, -1, s[1], s[2], n, s[3]//n])\n",
        "    # [MHWnc]  Calc stddev over group.\n",
        "    y -= tf.reduce_mean(y, axis=0, keepdims=True)\n",
        "    y = tf.reduce_mean(tf.square(y), axis=0)\n",
        "    y = tf.sqrt(y + 1e-8)\n",
        "    # [M11n]  Take average over fmaps and pixels.\n",
        "    y = tf.reduce_mean(y, axis=[1,2,4], keepdims=True)[:,:,:,:,0]\n",
        "    # [NHWn]  Replicate over group and pixels.\n",
        "    y = tf.tile(y, [G, s[1], s[2], 1])\n",
        "    # [NHWC]  Append as new fmap.\n",
        "    return tf.concat([x, y], axis=3)\n",
        "\n",
        "# 畳み込み層ごとの学習率を最適化するための細工 (Karras et al., 2018)\n",
        "class Conv2D(layers.Conv2D):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    kwargs['kernel_initializer'] = tf.keras.initializers.RandomNormal(stddev=1.)\n",
        "    super(Conv2D, self).__init__(*args, **kwargs)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    super(Conv2D, self).build(input_shape)\n",
        "    shape = self.kernel.shape.as_list()\n",
        "    self._normalization_constant = np.sqrt(2./(shape[0] * shape[1] * shape[2]))\n",
        "  \n",
        "  def call(self, x):\n",
        "    x = x * self._normalization_constant\n",
        "    x = super(Conv2D, self).call(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFuBQRrXDfb-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title データセットの準備\n",
        "\n",
        "# 画像のチャネル数（MNIST、Fashion-MNISTは1、カラー画像は3）\n",
        "input_channels = 1\n",
        "\n",
        "#Fashion-MNIST データセット\n",
        "import tensorflow_datasets as tfds\n",
        "#ds = tfds.image.mnist.FashionMNIST()\n",
        "ds = tfds.image.mnist.MNIST()\n",
        "ds.download_and_prepare()\n",
        "dataset = ds.as_dataset()['train']\n",
        "def preprocess(data):\n",
        "  img = tf.cast(data['image'], tf.float32)/255. * 2. - 1. #黒を-1.0、白を+1.0とする\n",
        "  return tf.image.resize_bilinear([img], (16, 16))[0], data['label']\n",
        "dataset = dataset.map(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMlmjmA4TBkI",
        "colab_type": "text"
      },
      "source": [
        "# 敵対的生成ネットワーク（Generative Adversarial Networks; GAN）\n",
        "\n",
        "乱数から画像を生成するgeneratorと、画像が本物か偽物かを判別するdiscriminatorが、互いに敵対するように構成されたネットワーク。\n",
        "\n",
        "### GANの研究開発に必要なもの\n",
        "- 機械学習の基礎知識\n",
        "- 人工ニューラルネットワークの知識\n",
        "- 計算リソース（GPUやそれを動かすためのフレームワークなど、今回はGoogle Colaboratory+TensorFlow）\n",
        "- GANの知識（今回の内容）\n",
        "\n",
        "### 用語集\n",
        "|用語（呼び方）|記号（数式）|説明|\n",
        "|:--|:--|:--|\n",
        "| real、本物 | $x$ | データセットから取り出される「本物」の画像 |\n",
        "| noise、乱数 | $z$ | Generatorに入力される乱数、常に乱数とは限らないので、隠れ変数（latent variable）とも |\n",
        "| generator、生成器 | $G$ | 乱数を入力とし画像を出力とする関数 |\n",
        "| discriminator、判別器 | $D$ | 画像を入力としスカラーを出力とする関数 |\n",
        "| fake、偽物 | $G(z)$ | Generatorが生成する「偽物」の画像 |\n",
        "|判別値、本物度| $D(x), D(G(z))$ | Discriminatorが表現する、画像の「本物度」 |\n",
        "\n",
        "### 今までの目的関数（おさらい）\n",
        "- 二次関数（単純に極小点に収束するという例でした）\n",
        "- 二つの関数の距離（一方はサンプルを生成している真の関数、もう一方はパラメータで表現した関数、後者を前者に「フィッティング」する）\n",
        "- クロスエントロピー（識別問題を関数のフィッティングとみたときの、二つの関数の距離のようなもの）\n",
        "\n",
        "### GANにおける二つの目的関数\n",
        "- Discriminatorの目的関数：Realの本物度は大きく、fakeの本物度は小さく。クロスエントロピーとほぼ同じ。\n",
        "- Generatorの目的関数：Fakeの本物度を大きくして、discriminatorを「騙そう」とする。こちらは関数のフィッティングとは少し異なる。\n",
        "\n",
        "同じ関数を一方では大きく、もう一方では小さくしようとするので敵対的（adversarial）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnTJjPHqXGHu",
        "colab_type": "text"
      },
      "source": [
        "# Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekyiUyr-mKHt",
        "colab_type": "text"
      },
      "source": [
        "機械学習はランダムに初期化された関数から初めて、目的関数を設定して勾配法によって良くして行く、という方法を取るので、とにかく入力からどのようにして出力を計算するか（フォワード経路）をまず考える。フォワード経路と目的関数さえ決めれば、勾配の計算（バックワード経路）とパラメータの更新はTensorFlowに任せられる。\n",
        "\n",
        "第一回の識別ネットワークと異なり、出力が画像となるので、幅と高さを大きくして行く方針を考える。画像の場合、チャネル数は最終的に１（グレースケール）か３（RGB）まで減らして行く。\n",
        "1. n個の乱数を生成（幅1、高さ1、チャネル数nの特徴マップと考える）\n",
        "2. 何回か畳み込み（Conv2D）を行う\n",
        "3. 各ピクセルを2x2ピクセルにコピーすることで、幅、高さをそれぞれ2倍にする（UpSampling2D）\n",
        "4. 目的の画像サイズになるまで2と3を繰り返す\n",
        "5. 各点ごとに目的のチャネル数（グレースケールなら1、RGBなら3）になるように1x1のカーネルで畳み込み（Conv2D）を行う\n",
        "6. ハイパボリックタンジェント（tanh）を使って出力値を(-1,+1)の範囲に制約する\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW8IpdSTCw8o",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title ハイパボリックタンジェント\n",
        "x = tf.linspace(-5.,5.,100)\n",
        "y = tf.tanh(x)\n",
        "plt.plot(x, y);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-vDcuTRimkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_dim = 128\n",
        "\n",
        "generator = tf.keras.Sequential([\n",
        "    Conv2D(256, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    PixelwiseNormalization(),\n",
        "\n",
        "    layers.UpSampling2D(2),\n",
        "    Conv2D(128, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    PixelwiseNormalization(),\n",
        "\n",
        "    layers.UpSampling2D(2),\n",
        "    Conv2D(64, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    PixelwiseNormalization(),\n",
        "\n",
        "    layers.UpSampling2D(2),\n",
        "    Conv2D(32, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    PixelwiseNormalization(),\n",
        "\n",
        "    layers.UpSampling2D(2),\n",
        "    Conv2D(16, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    PixelwiseNormalization(),\n",
        "\n",
        "    Conv2D(input_channels, [1,1], 1, 'SAME', use_bias=True),\n",
        "    layers.Activation('tanh')\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CbpXKQMXP5e",
        "colab_type": "text"
      },
      "source": [
        "##とにかく画像を学習させてみる（画像の丸暗記）\n",
        "\n",
        "畳み込みニューラルネットワークは画像を出力できるか？まずは関数のフィッティングで学習して確認してみる。\n",
        "\n",
        "入力が128次元なので、128個の単位ベクトル（$(1,0,\\cdots,0), (0,1,0,\\cdots,0),\\cdots$）に128枚の適当な画像を対応づけてみる。\n",
        "目的関数はgeneratorが生成した画像と正解画像との二乗誤差（mean squared error）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeAmLfmZDr5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.compile(tf.train.AdamOptimizer(0.001), loss='mean_squared_error')\n",
        "\n",
        "inputs = tf.one_hot(tf.range(noise_dim), noise_dim) # tf.one_hot(i)はe[i]だけ1.で他が0.のベクトル（つまり単位ベクトル）を生成\n",
        "inputs = tf.reshape(inputs, [noise_dim, 1, 1, noise_dim])\n",
        "for x, y in dataset.batch(noise_dim).take(1):\n",
        "  image = x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdFCIAzQGDk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.fit(x=inputs, y=image, epochs=1000, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lBPhviuH_YW",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title 正解画像と生成画像を比較\n",
        "y = generator(inputs)\n",
        "plt.figure(figsize=(15,5))\n",
        "n = 10\n",
        "for i in range(n):\n",
        "  plt.subplot(2,n,i+1)\n",
        "  plt.imshow(image[i,:,:,0])\n",
        "  plt.axis('off')\n",
        "  plt.subplot(2,n,n+i+1)\n",
        "  plt.imshow(y[i,:,:,0])\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exDxasbdJ3wR",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "1514a474-705e-441b-d75c-3fa285642fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#@title 入力を徐々に変化させてみる\n",
        "import numpy as np\n",
        "i1 = 0\n",
        "i2 = 1\n",
        "n = 10\n",
        "\n",
        "x = np.zeros([n,1,1,noise_dim], np.float32)\n",
        "x[:,0,0,i1] = np.linspace(0.,1.,n)\n",
        "x[:,0,0,i2] = np.linspace(1.,0.,n)\n",
        "y = generator(tf.constant(x))\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(n):\n",
        "  plt.subplot(1,n,i+1)\n",
        "  plt.imshow(y[i,:,:,0])\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAABoCAYAAAB19YgtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwRkAAAAAOIDBGQAAAAA44H8B3M3MYfeqYd0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1080x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUowkMUzL4Vx",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "5ba17bf9-f7c3-48e7-896c-bbb9260e3622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "#@title 任意の乱数について意味のある画像を生成できるか？\n",
        "n = 10\n",
        "y = generator(tf.random.normal([n,1,1,noise_dim]))\n",
        "plt.figure(figsize=(15,5))\n",
        "for i in range(n):\n",
        "  plt.subplot(1,n,i+1)\n",
        "  plt.imshow(y[i,:,:,0])\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAABoCAYAAAB19YgtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHq7CixzjJgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTTnVC9HA4pC",
        "colab_type": "text"
      },
      "source": [
        "- 128次元のベクトルを入力して画像を出力する関数が畳み込みニューラルネットワーク（CNN）で実現できた\n",
        "- このCNN単体でGANの機能を学習することはできない\n",
        "- この後discriminatorを構築し、GANのgeneratorとして動作させる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnXSPEhHabMQ",
        "colab_type": "text"
      },
      "source": [
        "# Discriminator\n",
        "\n",
        "Discriminatorは入力画像がデータセットから選ばれたもの（real）か、generatorが生成したもの（fake）かを学習する。\n",
        "Discriminator自体の学習は2クラスの分類問題となるので、前回の分類機と基本的に同じ。ただし、2クラスの場合、出力は一つの数値で良い。何故ならば、realであれば出力値を大きく、fakeであれば出力値を小さくすれば判別できるため。\n",
        "\n",
        "Generatorでは$1\\times1$の特徴マップ（入力乱数）から始めて、縦横を2倍にする演算（UpSampling2D）を繰り返すことで、一定サイズの画像を生成した。Discriminatorではこれと対称的に、縦横を半分にする演算（AveragePooling2D）を繰り返して特徴マップを小さくして行く方針をとる。\n",
        "\n",
        "1. $m\\times m \\times c$の画像を入力（cは画像のチャネル数）\n",
        "2. $1\\times1$のカーネルで畳み込んで$m\\times m \\times C$とする\n",
        "3. 何層かの畳み込み層（Conv2D）を計算\n",
        "4. 2x2ピクセルの領域ごとに平均をとることで、幅、高さをそれぞれ半分にする（AveragePooling2D）\n",
        "5. 特徴マップのサイズが$1\\times 1$になるまで3と4を繰り返す\n",
        "5. 判別値はスカラーなので、チャネル数が1になるように1x1のカーネルで畳み込み（Conv2D）を行う\n",
        "\n",
        "Generatorとdiscriminatorの構造は必ずしも対称的である必要はないが、対称的にされることが多い。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmeE-TGc1fTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator = tf.keras.Sequential([\n",
        "    Conv2D(16, [1,1], 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "\n",
        "    Conv2D(32, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    layers.AveragePooling2D(2),\n",
        "    \n",
        "    Conv2D(64, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    layers.AveragePooling2D(2),\n",
        "    \n",
        "    Conv2D(128, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    layers.AveragePooling2D(2),\n",
        "\n",
        "    Conv2D(256, 3, 1, 'SAME', use_bias=True),\n",
        "    layers.LeakyReLU(0.2),\n",
        "    layers.AveragePooling2D(2),\n",
        "\n",
        "    Conv2D(1, 3, 1, 'SAME', use_bias=False)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SO_6C3OjWw9C",
        "colab_type": "text"
      },
      "source": [
        "##本物と偽物を判別させてみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHyPdplxwyq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.compile(tf.train.AdamOptimizer(0.001), loss='binary_crossentropy')\n",
        "\n",
        "for x, y in dataset.batch(10000).take(1):\n",
        "  real = x\n",
        "fake = generator(tf.random.normal([10000,1,1,noise_dim]))\n",
        "inputs = tf.concat([real, fake], 0)\n",
        "outputs = tf.concat([tf.ones([10000,1,1,1]), tf.zeros([10000,1,1,1])], 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPA0ugo32kpz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.fit(x=inputs, y=outputs, epochs=10, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh8rdX-EMlA9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Discriminatorの出力\n",
        "for x, y in dataset.batch(1000).take(1):\n",
        "  d_real = discriminator(x)\n",
        "  d_fake = discriminator(generator(tf.random.normal([1000,1,1,noise_dim])))\n",
        "  plt.hist(d_real[:,0,0,0], label='real')\n",
        "  plt.hist(d_fake[:,0,0,0], label='fake')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8qefrxsuFDk",
        "colab_type": "text"
      },
      "source": [
        "# Generatorとdiscriminatorを戦わせる\n",
        "\n",
        "上のセルでは、discriminator（$D$）は、$D(x)$を大きくするように、$D(G(z))$を小さくするように学習している。これにより、$D$の値の大小で本物と偽物を見分けることができる。\n",
        "逆に、$D(G(z))$を大きくするような$G(z)$をgenerator（$G$）が生成できれば、それはdiscriminatorを騙したという意味で本物らしいということになる。\n",
        "ここで、discriminatorを再び学習させれば、本物らしくなった$G(z)$と$x$を見分けられるように判断基準を変えることになる。このとき、generatorは$D(G(z))$を大きくするために、その新たな判断基準でも見分けられないような$G(z)$を生成するように学習することになり…\n",
        "\n",
        "そこで、discriminatorが$D(x)$を大きく、$D(G(z))$を小さくするようにしながら、同時にgeneratorが$D(G(z))$を大きくするように学習することで、generatorとdiscriminatorが切磋琢磨しながら互いの精度を向上させて行くということが期待できる。これがGANの基本的な仕組みである。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JPTerCkK-eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "  return x\n",
        "\n",
        "# クロスエントロピーでフィッティングする場合\n",
        "#def f(x):\n",
        "#  return -tf.log1p(tf.exp(-x))\n",
        "\n",
        "@tf.contrib.eager.defun #これをつけた関数は最初の呼び出し時に最適化される\n",
        "def train_step(real, noise):\n",
        "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "    fake = generator(noise)\n",
        "\n",
        "    d_real = discriminator(real)\n",
        "    d_fake = discriminator(fake)\n",
        "\n",
        "    loss = f(d_real) + f(-d_fake)\n",
        "    g_loss = tf.reduce_mean(loss)\n",
        "    d_loss = tf.reduce_mean(-loss)\n",
        "\n",
        "  g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
        "  d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "  g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
        "  d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
        "  return d_loss\n",
        "\n",
        "g_opt = tf.train.AdamOptimizer(0.0002)\n",
        "d_opt = tf.train.AdamOptimizer(0.0002)\n",
        "epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLTUlNNaTAm7",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "for i in range(5):\n",
        "  t0 = time.time()\n",
        "  for x, y in dataset.shuffle(1000).batch(128):\n",
        "    loss = train_step(x, tf.random.normal([x.shape[0],1,1,noise_dim]))\n",
        "  t1 = time.time()\n",
        "  print(\"Epoch {}: loss={}, took {} sec.\".format(epoch, loss.numpy(), t1-t0))\n",
        "  epoch += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPoBC3q-Iq6_",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title バックグラウンドで実行\n",
        "\n",
        "import time\n",
        "import threading\n",
        "\n",
        "def train():\n",
        "  for i in range(5):\n",
        "    t0 = time.time()\n",
        "    for x, y in dataset.shuffle(1000).batch(128):\n",
        "      loss = train_step(x, tf.random.normal([x.shape[0],1,1,noise_dim]))\n",
        "    t1 = time.time()\n",
        "    print(\"Epoch {}: loss={}, took {} sec.\".format(epoch, loss.numpy(), t1-t0))\n",
        "    epoch += 1\n",
        "\n",
        "thread = threading.Thread(target=train)\n",
        "thread.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJey12-qI5dH",
        "colab_type": "text"
      },
      "source": [
        "# Mode collapse\n",
        "\n",
        "上記のように構成したGANは、確かに任意の乱数について手書き数字に見える画像を生成するが、全てが「１」であったりして、MNISTの画像を網羅しているとは言い難い。\n",
        "これはmode collapseと呼ばれる現象で、GANの分野では中心的とも言える大きな問題になっている。\n",
        "\n",
        "Mode collapseについて考えるためには、データセットに含まれる画像がどのように「分布」しているのかを理解する必要がある。\n",
        "例えば、MNISTの「１」にはバリエーションがあり、傾きや線の太さが異なるが、\n",
        "画像としては互いに似ていて、ある「１」から別の「１」まで滑らかに変化されることができる。\n",
        "一方、「１」から「０」へ滑らかに変化させることはできない。\n",
        "したがって、MNISTに含まれる画像の分布は、いくつかの「島」から成っていると考えられる。\n",
        "この「島」（の頂点）をmodeと呼ぶ。Mode collapseは、generatorが一部の「島」に属する画像を全く生成しないように学習してしまう現象。\n",
        "\n",
        "Mode collapseの原因の一つに、discriminatorの学習のし過ぎがある。\n",
        "Discriminatorの学習が進むと、「島」の内部では$D$の値が大きく、外部では$D$の値が小さくなる。Generatorは$D$の傾きを見ながら入島を目指すのだが、discriminatorが「島」の内外をあまりはっきりと区別してしまうと、「島」から離れたところでは$D$の値が常に小さく、どちらに行けば「島」に近づけるのかわからなくなる。\n",
        "たまたまいくつかの「島」に入っていれば、もはやその「島」からは出ることができず、他の「島」の探索はできなくなる。\n",
        "直感的に言えば、discriminatorがやっとのことで偽物の判別をしていれば、generatorはその判断基準を読んで今後の偽物品質を向上することができるが、\n",
        "discriminatorがあまりにも余裕綽々と判別をしてしまうと、generatorにはその判断基準が想像もつかなくなり、現状の偽物をどのように改良すればよいかわからなくなってしまう。\n",
        "\n",
        "初期に提案されたGANの手法は、ほとんどこのmode collapseの対策と言ってもいいほどで、これまでに様々な対策が提案されている。\n",
        "多くの手法で共通する方針は、discriminatorの判断基準を「緩やか」にするというもので、\n",
        "$D$の値が「島」の境界で急激に大きくなることを防ぎ、「島」から離れたところにも情報（$D$の傾き、すなわち判断基準）が届くようにする。\n",
        "今回はその方針に従っているものの中で実装が比較的簡単なquadratic potential（[Su, 2018](https://arxiv.org/pdf/1811.07296.pdf)）を適用してみる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYRgUTMh66IS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dの傾きを求める\n",
        "# これを小さくするようにdiscriminatorに制約をかける\n",
        "def quadratic_potential(dx, dy, _lambda=.01, _epsilon=1e-8, norm='L2'):\n",
        "  norm = norm.lower()\n",
        "  if norm == 'l1':\n",
        "    dx = tf.abs(dx)\n",
        "  elif norm == 'l2':\n",
        "    dx = tf.square(dx)\n",
        "  else:\n",
        "    raise ValueError('Unknown norm type: {}'.format(norm))\n",
        "\n",
        "  dx = tf.reduce_mean(tf.reshape(dx, [tf.shape(dx)[0],-1]))\n",
        "  if norm == 'l2':\n",
        "    dx = tf.sqrt(dx)\n",
        "\n",
        "  return tf.square(dy)/(dx*2*_lambda + _epsilon)\n",
        "\n",
        "@tf.contrib.eager.defun #これをつけた関数は最初の呼び出し時に最適化される\n",
        "def train_step(real, noise):\n",
        "  with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
        "    fake = generator(noise)\n",
        "\n",
        "    d_real = discriminator(real)\n",
        "    d_fake = discriminator(fake)\n",
        "\n",
        "    loss = f(d_real) + f(-d_fake)\n",
        "    g_loss = tf.reduce_mean(loss)\n",
        "    d_loss = tf.reduce_mean(-loss + quadratic_potential(fake-real, d_fake-d_real))\n",
        "\n",
        "  g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
        "  d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "  g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
        "  d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))\n",
        "  return d_loss\n",
        "\n",
        "epoch = 0\n",
        "g_opt = tf.train.AdamOptimizer(0.0002)\n",
        "d_opt = tf.train.AdamOptimizer(0.0002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EmVdO9-kcWq",
        "colab_type": "text"
      },
      "source": [
        "# 課題\n",
        "- ネットワーク構造をいじってみる\n",
        "  - チャネル数を増やしたらどうなる？\n",
        "  - カーネルのサイズを大きくしたらどうなる？\n",
        "  - 畳み込み層を増やしたらどうなる？\n",
        "- 学習率を変えてみる\n",
        "- Quadratic potentialの係数$\\lambda$(lambda)を変えてみる\n",
        "- データセットを変えてみる\n",
        "  - 「３」だけ学習させてみる\n",
        "  - Fashion MNISTにしてみる\n",
        "  - その他、カラーのデータセット（CIFARなど）にしてみる\n",
        "- 学習による生成画像の変化を追ってみる\n",
        "- 色々な画像の間を補間してみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp_qMcAAHDbk",
        "colab_type": "code",
        "outputId": "f509b495-5773-449c-a74e-f71679b06627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Googleドライブにgeneratorを保存\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "generator.save_weights('/gdrive/My Drive/gan_workshop/generator')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBXPb08oG-1G",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "7592b386-da52-492c-fd3a-04a5b59ca85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title Googleドライブからgeneratorを読み込み\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "generator.load_weights('/gdrive/My Drive/gan_workshop/generator')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f978f363f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}